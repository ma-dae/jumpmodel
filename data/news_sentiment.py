# news_sentiment.py
import pandas as pd
import requests
from datetime import date, timedelta
from pathlib import Path
import os
import json

# ğŸ“ ê²½ë¡œ ì„¤ì •
CONFIG_PATH = "config/sp500_companies.csv"
NEWS_DIR = Path("data/news")
NEWS_DIR.mkdir(parents=True, exist_ok=True)
LOG_PATH = NEWS_DIR / "failed_tickers.json"

# ğŸ“Œ ë‚ ì§œ ì„¤ì •
TODAY = date.today()
FROM_DATE = (TODAY - timedelta(days=7)).isoformat()
TO_DATE = TODAY.isoformat()

# ğŸ“„ API Key ì„¤ì • (NewsAPI)
NEWS_API_KEY = os.getenv("524a1766bfd74c48aee3a384c0dea908")  # í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • ê¶Œì¥
BASE_URL = "https://newsapi.org/v2/everything"

# ğŸ“„ S&P500 í‹°ì»¤ ë¶ˆëŸ¬ì˜¤ê¸°
try:
    sp500 = pd.read_csv(CONFIG_PATH)
    tickers = sp500['Symbol'].dropna().tolist()
except Exception as e:
    raise FileNotFoundError(f"[âŒ] ê¸°ì—… ë¦¬ìŠ¤íŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")

# =============================
# ğŸ”„ ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ (í‹°ì»¤ë³„)
# =============================
def fetch_news_newsapi(ticker):
    print(f"ğŸ“° {ticker}: ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
    params = {
        "q": ticker,
        "from": FROM_DATE,
        "to": TO_DATE,
        "sortBy": "publishedAt",
        "language": "en",
        "apiKey": NEWS_API_KEY,
        "pageSize": 100
    }
    try:
        response = requests.get(BASE_URL, params=params)
        data = response.json()
        if data.get("status") != "ok":
            raise ValueError(data.get("message", "API ì˜¤ë¥˜"))

        articles = data.get("articles", [])
        if not articles:
            print(f"   âš ï¸ {ticker}: ë‰´ìŠ¤ ì—†ìŒ")
            return pd.DataFrame()

        df = pd.DataFrame(articles)
        df['Ticker'] = ticker
        df = df.rename(columns={'publishedAt': 'providerPublishTime'})
        df['providerPublishTime'] = pd.to_datetime(df['providerPublishTime'])
        print(f"   âœ… {ticker}: {len(df)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
        return df[['Ticker', 'title', 'providerPublishTime']]

    except Exception as e:
        print(f"   âŒ {ticker} ìˆ˜ì§‘ ì‹¤íŒ¨ â†’ {e}")
        return pd.DataFrame()

# =============================
# ğŸ”„ í•˜ë£¨ 100ê°œì”© ìŠ¬ë¼ì´ì‹±
# =============================
def get_today_tickers(chunk_size=100):
    chunks = [tickers[i:i + chunk_size] for i in range(0, len(tickers), chunk_size)]
    today_index = TODAY.toordinal() % len(chunks)
    return chunks[today_index]

# =============================
# ğŸ”„ ì „ì²´ ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜
# =============================
def run_news_collection(selected_tickers=None):
    """
    ğŸ“Œ ë‰´ìŠ¤ ì „ì²´ ìˆ˜ì§‘ ì‹¤í–‰
    - selected_tickers: ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬ ê°€ëŠ¥
    """
    failed_tickers = []
    all_news_df = pd.DataFrame()

    if selected_tickers is None:
        tickers_to_process = get_today_tickers()
    else:
        tickers_to_process = selected_tickers

    print(f"[ğŸ“Š] ì˜¤ëŠ˜ ì²˜ë¦¬í•  ë‰´ìŠ¤ í‹°ì»¤ ìˆ˜: {len(tickers_to_process)}")
    for i, ticker in enumerate(tickers_to_process, 1):
        print(f"\n[{i}/{len(tickers_to_process)}] {ticker} ì²˜ë¦¬ ì¤‘...")
        news_df = fetch_news_newsapi(ticker)
        if not news_df.empty:
            all_news_df = pd.concat([all_news_df, news_df], ignore_index=True)
        else:
            failed_tickers.append({"ticker": ticker, "reason": "empty or error"})

    # ì €ì¥
    output_path = NEWS_DIR / f"news_sentiment_{TODAY}.csv"
    all_news_df.to_csv(output_path, index=False)
    print(f"\nğŸ’¾ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ â†’ {output_path}")
    print(f"ğŸ“Š ì´ ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {len(all_news_df)}ê°œ")

    # ì‹¤íŒ¨ ë¡œê·¸ ì €ì¥
    if failed_tickers:
        with open(LOG_PATH, "w", encoding="utf-8") as f:
            json.dump(failed_tickers, f, indent=2, ensure_ascii=False)
        print(f"[ğŸ“Œ] ì‹¤íŒ¨í•œ ì¢…ëª© {len(failed_tickers)}ê°œ ê¸°ë¡ë¨ â†’ {LOG_PATH}")
