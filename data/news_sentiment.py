# news_sentiment.py
import os
import json
import pandas as pd
import datetime
from pathlib import Path
from newsapi import NewsApiClient  # pip install newsapi-python

# ğŸ“ í™˜ê²½ì„¤ì •
CONFIG_PATH = "config/sp500_companies.csv"
NEWS_DATA_DIR = Path("data/news")
NEWS_DATA_DIR.mkdir(parents=True, exist_ok=True)
LOG_PATH = NEWS_DATA_DIR / "failed_news_tickers.json"

# ğŸ“Œ ë‰´ìŠ¤API í‚¤ (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ì§ì ‘ ì…ë ¥)
NEWSAPI_KEY = os.getenv("NEWSAPI_KEY") or "524a1766bfd74c48aee3a384c0dea908"
newsapi = NewsApiClient(api_key=NEWSAPI_KEY)

# =============================
# ğŸ”„ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ê°ì„± ë¶„ì„
# =============================
def run_news_collection(days_back: int = 30):
    """S&P500 í‹°ì»¤ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° FinBERT ê°ì„± ë¶„ì„"""
    
    # í‹°ì»¤ ë¶ˆëŸ¬ì˜¤ê¸°
    sp500 = pd.read_csv(CONFIG_PATH)
    tickers = sp500['Symbol'].dropna().unique().tolist()
    print(f"[ğŸ“Š] {len(tickers)}ê°œ í‹°ì»¤ ë¡œë“œ ì™„ë£Œ")

    failed_tickers = []
    all_news_df = pd.DataFrame()

    # ë‚ ì§œ ë²”ìœ„
    to_date = datetime.datetime.now()
    from_date = to_date - datetime.timedelta(days=days_back)
    from_str = from_date.strftime("%Y-%m-%d")
    to_str = to_date.strftime("%Y-%m-%d")

    # FinBERT ë¡œë”©
    try:
        from transformers import pipeline
        sentiment_pipeline = pipeline(
            "sentiment-analysis",
            model="yiyanghkust/finbert-tone",
            tokenizer="yiyanghkust/finbert-tone"
        )
        print("âœ… FinBERT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"[âŒ] FinBERT ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    for i, ticker in enumerate(tickers, 1):
        print(f"\n[{i}/{len(tickers)}] {ticker}: ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
        try:
            news_results = newsapi.get_everything(
                q=ticker,
                from_param=from_str,
                to=to_str,
                language='en',
                sort_by='relevancy',
                page_size=100  # ìµœëŒ€ 100ê°œ
            )

            articles = news_results.get('articles', [])
            if not articles:
                print(f"[âš ï¸] {ticker}: ë‰´ìŠ¤ ì—†ìŒ")
                failed_tickers.append({"ticker": ticker, "reason": "empty"})
                continue

            df = pd.DataFrame(articles)
            df['Ticker'] = ticker
            df = df[['Ticker', 'title', 'publishedAt']].rename(columns={'publishedAt': 'Date'})
            df['Date'] = pd.to_datetime(df['Date'])

            # ê°ì„± ë¶„ì„
            sentiments = []
            for text in df['title']:
                result = sentiment_pipeline(text)[0]
                label = result['label'].lower()
                score = result['score']
                if label == "positive":
                    sentiments.append(score)
                elif label == "negative":
                    sentiments.append(-score)
                else:
                    sentiments.append(0.0)
            df['news_sentiment_score'] = sentiments

            # ê¸ì • í‚¤ì›Œë“œ ë“±ì¥ íšŸìˆ˜
            df['positive_keywords_count'] = df['title'].str.count(r'\b(earnings|growth|merger|acquisition|contract)\b')

            all_news_df = pd.concat([all_news_df, df], ignore_index=True)
            print(f"[âœ…] {ticker}: {len(df)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ê°ì„± ë¶„ì„ ì™„ë£Œ")

        except Exception as e:
            print(f"[ğŸ’¥] {ticker}: ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨ â†’ {e}")
            failed_tickers.append({"ticker": ticker, "reason": str(e)})

    # CSV ì €ì¥
    output_path = NEWS_DATA_DIR / "news_sentiment_features.csv"
    all_news_df.to_csv(output_path, index=False)
    print(f"\nğŸ’¾ ëª¨ë“  ë‰´ìŠ¤ ì €ì¥ ì™„ë£Œ â†’ {output_path}")
    print(f"ğŸ“Š ì´ ë‰´ìŠ¤: {len(all_news_df)}ê°œ")

    # ì‹¤íŒ¨ í‹°ì»¤ ê¸°ë¡
    if failed_tickers:
        with open(LOG_PATH, "w", encoding="utf-8") as f:
            json.dump(failed_tickers, f, indent=2, ensure_ascii=False)
        print(f"[ğŸ“Œ] ì‹¤íŒ¨ í‹°ì»¤ {len(failed_tickers)}ê°œ ê¸°ë¡ë¨ â†’ {LOG_PATH}")

# =============================
# ğŸ”„ ë…ë¦½ ì‹¤í–‰
# =============================
if __name__ == "__main__":
    run_news_collection(days_back=30)
