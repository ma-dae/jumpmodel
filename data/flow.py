# flow.py
import pandas as pd
from pathlib import Path
import glob
import traceback

# ğŸ“ ê²½ë¡œ ì„¤ì •
CLEAN_DATA_DIR = Path("data/clean")
NEWS_DATA_DIR = Path("data/news")
MERGE_DIR = Path("data/merged")
MERGE_DIR.mkdir(parents=True, exist_ok=True)

# =============================
# ğŸ” ìœ í‹¸: ìµœì‹  ë‰´ìŠ¤ íŒŒì¼ ì°¾ê¸°
# =============================
def find_latest_news_file():
    # ìš°ì„  ê³ ì • ì´ë¦„ ì‹œë„
    candidate = NEWS_DATA_DIR / "news_sentiment_features.csv"
    if candidate.exists():
        return candidate

    # íŒ¨í„´ìœ¼ë¡œ ê²€ìƒ‰ (ì˜ˆ: news_sentiment_2025-09-30.csv ë“±)
    pattern = str(NEWS_DATA_DIR / "news_sentiment*.csv")
    files = glob.glob(pattern)
    if not files:
        return None
    # ìµœì‹  íŒŒì¼ ë°˜í™˜
    files_sorted = sorted(files, key=lambda p: Path(p).stat().st_mtime, reverse=True)
    return Path(files_sorted[0])

# =============================
# ğŸ”„ í‹°ì»¤ë³„ feature merge
# =============================
def merge_features(tickers):
    """
    ğŸ“Œ CLEAN ë°ì´í„° + ë‰´ìŠ¤ ê°ì„± ë°ì´í„° ë³‘í•© (ë°©ì–´ì  êµ¬í˜„)
      - ë‰´ìŠ¤ íŒŒì¼ ìë™ ê²€ìƒ‰ (ê³ ì • ì´ë¦„ ìš°ì„ , ì—†ìœ¼ë©´ patternìœ¼ë¡œ ìµœì‹  íŒŒì¼ ì‚¬ìš©)
      - ë‰´ìŠ¤ì— ì—¬ëŸ¬ ë‚ ì§œ ì¹¼ëŸ¼ ê°€ëŠ¥ì„± ëŒ€ì‘ (providerPublishTime, publishedAt, datetime ë“±)
      - ë‚ ì§œë¥¼ date ë‹¨ìœ„ë¡œ í†µì¼í•˜ì—¬ ë³‘í•©
      - ë‰´ìŠ¤ê°€ ì—†ê±°ë‚˜ í•´ë‹¹ í‹°ì»¤ ë‰´ìŠ¤ê°€ ì—†ì„ ê²½ìš° CLEAN ë°ì´í„°ë§Œ ì €ì¥
    """
    news_file = find_latest_news_file()
    if news_file is None:
        print(f"[âš ï¸] ë‰´ìŠ¤ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {NEWS_DATA_DIR}")
        news_df = None
    else:
        print(f"[ğŸ“Š] ë‰´ìŠ¤ íŒŒì¼ ë¡œë“œ: {news_file}")
        try:
            news_df = pd.read_csv(news_file)
            # ì†Œë¬¸ì ì»¬ëŸ¼ ì •ê·œí™”(ì„ íƒì ) - ë³´ìˆ˜ì ìœ¼ë¡œ ìœ ì§€
            print(f"     ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(news_df)}í–‰")
        except Exception as e:
            print(f"[âŒ] ë‰´ìŠ¤ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            news_df = None

    # í›„ë³´ ë‚ ì§œ ì¹¼ëŸ¼ ëª©ë¡ (ìš°ì„ ìˆœìœ„)
    possible_date_cols = ["providerPublishTime", "publishedAt", "datetime", "date", "Date"]

    for i, ticker in enumerate(tickers, 1):
        print(f"\n[{i}/{len(tickers)}] {ticker} ë³‘í•© ì‹œì‘...")
        clean_path = CLEAN_DATA_DIR / f"{ticker}.csv"
        if not clean_path.exists():
            print(f"[âŒ] {ticker}: clean íŒŒì¼ ì—†ìŒ ({clean_path}) â€” ê±´ë„ˆëœ€")
            continue

        try:
            df_clean = pd.read_csv(clean_path)
            # Date ì¹¼ëŸ¼ì´ ì—†ê±°ë‚˜ í˜•ì‹ ë¬¸ì œ ë°©ì§€
            if "Date" not in df_clean.columns:
                # ì‹œë„: indexê°€ ë‚ ì§œì¼ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ ê·¸ëƒ¥ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
                print(f"[âš ï¸] {ticker}: clean íŒŒì¼ì— 'Date' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í™•ì¸ í•„ìš”.")
                # ê·¸ë˜ë„ ì €ì¥í•´ì„œ ì§„í–‰ì¤‘ì¸ ìƒíƒœ ìœ ì§€
                df_merge = df_clean.copy()
                merge_path = MERGE_DIR / f"{ticker}_merged.csv"
                df_merge.to_csv(merge_path, index=False)
                print(f"[âœ…] {ticker}: clean ê·¸ëŒ€ë¡œ ì €ì¥ â†’ {merge_path}")
                continue

            # Date í‘œì¤€í™”: pandas datetime -> date (ë…„-ì›”-ì¼)
            df_clean['Date'] = pd.to_datetime(df_clean['Date'], errors='coerce').dt.date
            df_clean['Ticker'] = ticker  # ë³‘í•© í¸ì˜ìš©

            if news_df is None or news_df.empty:
                # ë‰´ìŠ¤ ë°ì´í„° ì—†ìŒ: cleanë§Œ ì €ì¥
                df_merge = df_clean.copy()
                merge_path = MERGE_DIR / f"{ticker}_merged.csv"
                df_merge.to_csv(merge_path, index=False)
                print(f"[âœ…] {ticker}: ë‰´ìŠ¤ ì—†ìŒ â€” cleanë§Œ ì €ì¥ â†’ {merge_path}")
                continue

            # í‹°ì»¤ë³„ ë‰´ìŠ¤ í•„í„°
            df_news_ticker = news_df[news_df.get('Ticker', '') == ticker].copy()
            if df_news_ticker.empty:
                print(f"[âš ï¸] {ticker}: ë‰´ìŠ¤ íŒŒì¼ì—ëŠ” í‹°ì»¤ë³„ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤. cleanë§Œ ì €ì¥")
                df_merge = df_clean.copy()
                merge_path = MERGE_DIR / f"{ticker}_merged.csv"
                df_merge.to_csv(merge_path, index=False)
                print(f"[âœ…] {ticker}: clean ì €ì¥ â†’ {merge_path}")
                continue

            # ë‚ ì§œ ì»¬ëŸ¼ ìë™ íƒìƒ‰
            right_date_col = None
            for col in possible_date_cols:
                if col in df_news_ticker.columns:
                    right_date_col = col
                    break

            if right_date_col is None:
                print(f"[âš ï¸] {ticker}: ë‰´ìŠ¤ ë°ì´í„°ì— ë‚ ì§œ ì¹¼ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ì¹¼ëŸ¼: {possible_date_cols}")
                print("       -> cleanë§Œ ì €ì¥")
                df_merge = df_clean.copy()
                merge_path = MERGE_DIR / f"{ticker}_merged.csv"
                df_merge.to_csv(merge_path, index=False)
                print(f"[âœ…] {ticker}: clean ì €ì¥ â†’ {merge_path}")
                continue

            # í‘œì¤€í™”: ë‰´ìŠ¤ ë‚ ì§œë¥¼ date ë‹¨ìœ„ë¡œ ë³€í™˜
            df_news_ticker[right_date_col] = pd.to_datetime(df_news_ticker[right_date_col], errors='coerce')
            df_news_ticker = df_news_ticker.dropna(subset=[right_date_col])
            df_news_ticker['Date'] = df_news_ticker[right_date_col].dt.date

            # í•„ìš”í•œ ë‰´ìŠ¤ ì»¬ëŸ¼ ì„ íƒ(ì•ˆì •ì„± í™•ë³´)
            news_cols = [c for c in ['Date','news_sentiment_score','positive_keywords_count','title','url'] if c in df_news_ticker.columns]
            if 'Date' not in news_cols:
                news_cols = ['Date'] + news_cols  # ensure Date included

            df_news_small = df_news_ticker[news_cols].drop_duplicates(subset=['Date'])
            # ë³‘í•©: Date + Ticker (df_clean already has Ticker)
            df_merge = pd.merge(df_clean, df_news_small, on='Date', how='left')

            # ì €ì¥
            merge_path = MERGE_DIR / f"{ticker}_merged.csv"
            df_merge.to_csv(merge_path, index=False)
            print(f"[âœ…] {ticker}: merge ì™„ë£Œ â†’ {merge_path} (rows: {len(df_merge)})")

        except Exception as e:
            print(f"[ğŸ’¥] {ticker}: ë³‘í•© ë„ì¤‘ ì˜¤ë¥˜ ë°œìƒ â†’ {e}")
            traceback.print_exc()
            # ì‹¤íŒ¨í•´ë„ ë‹¤ìŒ í‹°ì»¤ë¡œ ì§„í–‰
            continue

    print("\n[ğŸ‰] ì „ì²´ ë³‘í•© ì‘ì—… ì™„ë£Œ!")

# =============================
# ğŸ”„ ë…ë¦½ ì‹¤í–‰
# =============================
if __name__ == "__main__":
    tickers = [f.stem for f in CLEAN_DATA_DIR.glob("*.csv")]
    merge_features(tickers)
