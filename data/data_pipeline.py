# daily_pipeline.py
from raw import run_raw_collection
from preprocess import run_all_preprocess
from news_sentiment import run_news_collection
from flow import merge_features
from feature_engineering import run_feature_engineering
from pathlib import Path
import datetime

# ğŸ“ ê²½ë¡œ ì„¤ì •
CLEAN_DATA_DIR = Path("data/clean")

# =============================
# ğŸ”„ í•˜ë£¨ ë‰´ìŠ¤ í‹°ì»¤ ìŠ¬ë¼ì´ì‹±
# =============================
def get_ticker_slice(all_tickers, chunk_size=100):
    """
    ğŸ“Œ í•˜ë£¨ì— 100ê°œ í‹°ì»¤ë§Œ ë‰´ìŠ¤ ìˆ˜ì§‘í•˜ë„ë¡ ìŠ¬ë¼ì´ì‹±
    - ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ "nì¼ì°¨"ë¥¼ ê³„ì‚°í•´ì„œ êµ¬ê°„ ê²°ì •
    """
    today = datetime.date.today()
    day_number = (today - datetime.date(2025, 9, 30)).days + 1  # ê¸°ì¤€ ë‚ ì§œ
    total_chunks = (len(all_tickers) // chunk_size) + 1
    start = ((day_number - 1) % total_chunks) * chunk_size
    end = min(start + chunk_size, len(all_tickers))
    return all_tickers[start:end]

# =============================
# ğŸ”„ Daily Pipeline
# =============================
if __name__ == "__main__":
    print("\n=== 1ï¸âƒ£ RAW ë°ì´í„° ìˆ˜ì§‘ ===")
    run_raw_collection()

    print("\n=== 2ï¸âƒ£ ì „ì²˜ë¦¬ ë‹¨ê³„ ===")
    all_tickers = [f.stem for f in Path("data/raw").glob("*.csv")]
    run_all_preprocess(all_tickers)

    print("\n=== 3ï¸âƒ£ ë‰´ìŠ¤ + ê°ì„± ë¶„ì„ ===")
    selected_tickers = get_ticker_slice(all_tickers, chunk_size=100)
    print(f"[ğŸ“°] ì˜¤ëŠ˜ ì²˜ë¦¬í•  ë‰´ìŠ¤ í‹°ì»¤ ê°œìˆ˜: {len(selected_tickers)}")
    print(f"[ğŸ“°] ì˜¤ëŠ˜ ëŒ€ìƒ í‹°ì»¤: {selected_tickers[:5]} ...")  # ì•ë¶€ë¶„ ìƒ˜í”Œ ì¶œë ¥
    run_news_collection(selected_tickers)

    print("\n=== 4ï¸âƒ£ Feature merge ===")
    tickers_clean = [f.stem for f in CLEAN_DATA_DIR.glob("*.csv")]
    merge_features(tickers_clean)

    print("\n=== 5ï¸âƒ£ Featureì…‹ ìƒì„± ===")
    tickers_merged = [f.stem.replace("_merged","") for f in Path("data/merged").glob("*.csv")]
    run_feature_engineering(tickers_merged, use_news=True)

    print("\n=== âœ… Daily pipeline ì™„ë£Œ! ===")
